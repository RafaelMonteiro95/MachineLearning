{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(object):\n",
    "    model = None\n",
    "\n",
    "    @staticmethod\n",
    "    def f(net):\n",
    "        return ( 1/ (1+ np.exp(-net)) )\n",
    "\n",
    "    @staticmethod\n",
    "    def df_dnet(f_net):\n",
    "        return ( f_net * (1 - f_net) )\n",
    "\n",
    "    def __init__(self, input_length=2, hidden_length=3, output_length=1, activation_function=f , d_activation_function=df_dnet):\n",
    "        self.architecture(input_length, hidden_length, output_length, activation_function, d_activation_function)\n",
    "\n",
    "    def architecture(self, input_length=2, hidden_length=3, output_length=1, activation_function=f , d_activation_function=df_dnet ):\n",
    "        self.model = {\n",
    "            'input_length': input_length, \n",
    "            'hidden_length': hidden_length, \n",
    "            'output_length': output_length, \n",
    "            'activation_function': activation_function.__func__, \n",
    "            'd_activation_function': d_activation_function.__func__,\n",
    "            'hidden': (np.random.rand(hidden_length, input_length+1) - 0.5),\n",
    "            'output': (np.random.rand(output_length, hidden_length+1) - 0.5),\n",
    "        }\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Recuperando valores do modelo\n",
    "        hidden = self.model['hidden']\n",
    "        output = self.model['output']\n",
    "        f = self.model['activation_function']\n",
    "        # Adicionando 1 para multiplicar o Theta.\n",
    "        X = np.pad(x, (0, 1), 'constant', constant_values=(1))\n",
    "\n",
    "        # Camada Escondida\n",
    "        net_h = np.sum(np.multiply(hidden, X), axis=1)\n",
    "        f_net_h = f(net_h)\n",
    "\n",
    "        # Camada de Saída\n",
    "        cf_net_h = np.pad(f_net_h, (0, 1), 'constant', constant_values=(1))\n",
    "        net_o = np.sum(np.multiply(output, cf_net_h), axis=1)\n",
    "        f_net_o = f(net_o)\n",
    "\n",
    "        # Retornando valores do forward.\n",
    "        return {\n",
    "            'net_h': net_h,\n",
    "            'f_net_h': f_net_h,\n",
    "            'net_o': net_o,\n",
    "            'f_net_o': f_net_o,\n",
    "        }\n",
    "\n",
    "    def backpropagation(self, X, Y, eta=0.1, threshold=1e-3):\n",
    "        squaredError = 2*threshold\n",
    "        df_dnet = self.model['d_activation_function']\n",
    "        output = self.model['output']\n",
    "        hidden = self.model['hidden']\n",
    "        hidden_length = self.model['hidden_length']\n",
    "        counter = 0\n",
    "        while(squaredError > threshold):\n",
    "            squaredError = 0\n",
    "            # Pra cada valor do conjunto de dados\n",
    "            for x, y in zip(X, Y):\n",
    "                # Calculando saída\n",
    "                results = self.forward(x)\n",
    "                output = results['f_net_o']\n",
    "                #  Calculando o erro\n",
    "                error = y - output\n",
    "                squaredError += np.sum(np.power(error, 2))\n",
    "\n",
    "                # Backwards camada de saída\n",
    "                delta_o = error * df_dnet(results['f_net_o'])\n",
    "\n",
    "                # Backwards camada escondida\n",
    "                w_o_kj = self.model['output'][:,0:hidden_length] \n",
    "                delta_h = np.array([df_dnet(results['f_net_h']) * np.dot(delta_o, w_o_kj)])\n",
    "\n",
    "                # Treinamento\n",
    "                f_net_h = np.pad(results['f_net_h'], (0, 1), 'constant', constant_values=(1))\n",
    "                self.model['output'] = self.model['output'] + eta * np.multiply(np.array([delta_o]).T, np.array([f_net_h]))\n",
    "                self.model['hidden'] = self.model['hidden'] + eta * np.multiply(delta_h.T, np.pad(x, (0, 1), 'constant', constant_values=(1)))\n",
    "\n",
    "            squaredError = squaredError / len(X) \n",
    "            counter += 1\n",
    "            if(counter % 1000 == 0):\n",
    "                print('error %.6lf - iter. %d' % (squaredError, counter))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error 0.256889 - iter. 1000\n",
      "error 0.016054 - iter. 2000\n",
      "error 0.002772 - iter. 3000\n",
      "error 0.001420 - iter. 4000\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "xor_x = np.array([0, 0, 0, 1, 1, 0, 1, 1]).reshape((4,2))\n",
    "xor_y = np.array([x[0]^x[1] for x in xor_x])\n",
    "\n",
    "mlp = MLP()\n",
    "mlp.backpropagation(xor_x, xor_y, eta=0.5)\n",
    "\n",
    "for x, y in zip(xor_x, xor_y):\n",
    "    print(y == round(mlp.forward(x)['f_net_o'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error 0.146909 - iter. 1000\n",
      "error 0.069828 - iter. 2000\n",
      "error 0.045556 - iter. 3000\n",
      "error 0.033737 - iter. 4000\n",
      "error 0.026761 - iter. 5000\n",
      "error 0.022162 - iter. 6000\n",
      "error 0.018905 - iter. 7000\n",
      "error 0.016478 - iter. 8000\n",
      "error 0.014601 - iter. 9000\n",
      "error 0.013105 - iter. 10000\n",
      "error 0.011887 - iter. 11000\n",
      "error 0.010874 - iter. 12000\n",
      "error 0.010020 - iter. 13000\n",
      "error 0.009290 - iter. 14000\n",
      "error 0.008659 - iter. 15000\n",
      "error 0.008107 - iter. 16000\n",
      "error 0.007622 - iter. 17000\n",
      "error 0.007191 - iter. 18000\n",
      "error 0.006806 - iter. 19000\n",
      "error 0.006460 - iter. 20000\n",
      "error 0.006147 - iter. 21000\n",
      "error 0.005863 - iter. 22000\n",
      "error 0.005604 - iter. 23000\n",
      "error 0.005367 - iter. 24000\n",
      "error 0.005149 - iter. 25000\n",
      "error 0.004948 - iter. 26000\n",
      "error 0.004762 - iter. 27000\n",
      "error 0.004590 - iter. 28000\n",
      "error 0.004429 - iter. 29000\n",
      "error 0.004280 - iter. 30000\n",
      "error 0.004140 - iter. 31000\n",
      "error 0.004009 - iter. 32000\n",
      "error 0.003886 - iter. 33000\n",
      "error 0.003770 - iter. 34000\n",
      "error 0.003661 - iter. 35000\n",
      "error 0.003558 - iter. 36000\n",
      "error 0.003460 - iter. 37000\n",
      "error 0.003368 - iter. 38000\n",
      "error 0.003281 - iter. 39000\n",
      "error 0.003198 - iter. 40000\n",
      "error 0.003119 - iter. 41000\n",
      "error 0.003044 - iter. 42000\n",
      "error 0.002972 - iter. 43000\n",
      "error 0.002904 - iter. 44000\n",
      "error 0.002839 - iter. 45000\n",
      "error 0.002776 - iter. 46000\n",
      "error 0.002717 - iter. 47000\n",
      "error 0.002659 - iter. 48000\n",
      "error 0.002605 - iter. 49000\n",
      "error 0.002552 - iter. 50000\n",
      "error 0.002501 - iter. 51000\n",
      "error 0.002453 - iter. 52000\n",
      "error 0.002406 - iter. 53000\n",
      "error 0.002361 - iter. 54000\n",
      "error 0.002318 - iter. 55000\n",
      "error 0.002276 - iter. 56000\n",
      "error 0.002236 - iter. 57000\n",
      "error 0.002197 - iter. 58000\n",
      "error 0.002159 - iter. 59000\n",
      "error 0.002123 - iter. 60000\n",
      "error 0.002088 - iter. 61000\n",
      "error 0.002054 - iter. 62000\n",
      "error 0.002021 - iter. 63000\n",
      "error 0.001989 - iter. 64000\n",
      "error 0.001958 - iter. 65000\n",
      "error 0.001928 - iter. 66000\n",
      "error 0.001899 - iter. 67000\n",
      "error 0.001871 - iter. 68000\n",
      "error 0.001843 - iter. 69000\n",
      "error 0.001817 - iter. 70000\n",
      "error 0.001791 - iter. 71000\n",
      "error 0.001766 - iter. 72000\n",
      "error 0.001742 - iter. 73000\n",
      "error 0.001718 - iter. 74000\n",
      "error 0.001695 - iter. 75000\n",
      "error 0.001672 - iter. 76000\n",
      "error 0.001650 - iter. 77000\n",
      "error 0.001629 - iter. 78000\n",
      "error 0.001608 - iter. 79000\n",
      "error 0.001588 - iter. 80000\n",
      "error 0.001568 - iter. 81000\n",
      "error 0.001549 - iter. 82000\n",
      "error 0.001530 - iter. 83000\n",
      "error 0.001512 - iter. 84000\n",
      "error 0.001494 - iter. 85000\n",
      "error 0.001476 - iter. 86000\n",
      "error 0.001459 - iter. 87000\n",
      "error 0.001443 - iter. 88000\n",
      "error 0.001426 - iter. 89000\n",
      "error 0.001410 - iter. 90000\n",
      "error 0.001395 - iter. 91000\n",
      "error 0.001379 - iter. 92000\n",
      "error 0.001364 - iter. 93000\n",
      "error 0.001350 - iter. 94000\n",
      "error 0.001335 - iter. 95000\n",
      "error 0.001321 - iter. 96000\n",
      "error 0.001308 - iter. 97000\n",
      "error 0.001294 - iter. 98000\n",
      "error 0.001281 - iter. 99000\n",
      "error 0.001268 - iter. 100000\n",
      "error 0.001256 - iter. 101000\n",
      "error 0.001243 - iter. 102000\n",
      "error 0.001231 - iter. 103000\n",
      "error 0.001219 - iter. 104000\n",
      "error 0.001207 - iter. 105000\n",
      "error 0.001196 - iter. 106000\n",
      "error 0.001185 - iter. 107000\n",
      "error 0.001174 - iter. 108000\n",
      "error 0.001163 - iter. 109000\n",
      "error 0.001152 - iter. 110000\n",
      "error 0.001142 - iter. 111000\n",
      "error 0.001131 - iter. 112000\n",
      "error 0.001121 - iter. 113000\n",
      "error 0.001111 - iter. 114000\n",
      "error 0.001102 - iter. 115000\n",
      "error 0.001092 - iter. 116000\n",
      "error 0.001083 - iter. 117000\n",
      "error 0.001073 - iter. 118000\n",
      "error 0.001064 - iter. 119000\n",
      "error 0.001055 - iter. 120000\n",
      "error 0.001047 - iter. 121000\n",
      "error 0.001038 - iter. 122000\n",
      "error 0.001030 - iter. 123000\n",
      "error 0.001021 - iter. 124000\n",
      "error 0.001013 - iter. 125000\n",
      "error 0.001005 - iter. 126000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 10 # Tamanho da matriz \n",
    "X = np.identity(n) # Matriz identidade de entrada\n",
    "Y = np.identity(n) # Matriz identidade de saída\n",
    "hidden_length = int(np.log2(n)) # Número de neurônios na camada de saída\n",
    "input_length = X.size # Número de neurônios de entrada\n",
    "output_length = Y.size # Número de neurônios de saída\n",
    "\n",
    "# Iniciando modelo da rede MLP\n",
    "mlp = MLP(input_length=input_length, hidden_length=hidden_length, output_length=output_length)\n",
    "# Backpropagation - Treinamento da MLP\n",
    "mlp.backpropagation([X.flat], [Y.flat])\n",
    "# Printando saída da rede, arredondando valores para inteiros.\n",
    "np.rint(mlp.forward(Y.flat)['f_net_o']).reshape((n,n))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
